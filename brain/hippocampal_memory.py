#!/usr/bin/env python3
"""
Harry-001 Memory Consolidation System
ä»¿ç…§æµ·é¦¬é«”çš„è¨˜æ†¶éå›ºæ©Ÿåˆ¶
Inspired by hippocampal memory consolidation

Created: 2026-02-07
"""

import time
import hashlib
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Any
from collections import deque
import json


@dataclass
class MemoryItem:
    """è¨˜æ†¶é …ç›®"""
    id: str
    content: Any
    memory_type: str  # 'episodic', 'semantic', 'procedural'
    importance: float  # 0-1
    access_count: int = 0
    last_accessed: float = field(default_factory=time.time)
    created_at: float = field(default_factory=time.time)
    consolidation_level: int = 0  # 0-3 (short-term â†’ long-term)
    emotional_valence: float = 0.0  # positive/negative charge
    context_tags: List[str] = field(default_factory=list)
    
    def to_dict(self):
        return {
            'id': self.id,
            'content': str(self.content)[:100],
            'type': self.memory_type,
            'importance': self.importance,
            'access_count': self.access_count,
            'consolidation': self.consolidation_level,
            'last_access': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(self.last_accessed))
        }


@dataclass
class ConsolidationResult:
    """éå›ºçµæœ"""
    promoted_memories: List[str]
    demoted_memories: List[str]
    new_insights: List[str]
    total_energy_spent: float


class HippocampalMemory:
    """
    æµ·é¦¬é«”è¨˜æ†¶ç³»çµ±
    ä»¿ç…§:
    - çŸ­æœŸè¨˜æ†¶ â†’ é•·æœŸè¨˜æ†¶ çš„è½‰æ›
    - æƒ…å¢ƒç¶å®š (contextual binding)
    - è¨˜æ†¶é‡çµ„ (memory replay during sleep)
    """
    
    def __init__(self):
        # çŸ­æœŸè¨˜æ†¶ç·©è¡å€ (é¡ä¼¼ CA3 å€)
        self.short_term_buffer: Dict[str, MemoryItem] = {}
        
        # é•·æœŸè¨˜æ†¶å­˜å„² (é¡ä¼¼çš®å±¤)
        self.long_term_memory: Dict[str, MemoryItem] = {}
        
        # è¨˜æ†¶ç—•è·¡ (spaced repetition traces)
        self.memory_traces: Dict[str, deque] = {}  # access history
        
        # çµ±è¨ˆ
        self.stats = {
            'total_memories': 0,
            'consolidations': 0,
            'promoted_to_ltm': 0,
            'forgotten': 0
        }
        
    def store(self, content: Any, memory_type: str = 'episodic', 
              importance: float = 0.5, emotional_valence: float = 0.0,
              context_tags: List[str] = None) -> str:
        """å­˜å„²æ–°è¨˜æ†¶"""
        mem_id = self._generate_id(content)
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if mem_id in self.short_term_buffer or mem_id in self.long_term_memory:
            # å¼·åŒ–ç¾æœ‰è¨˜æ†¶
            self._reinforce(mem_id)
            return mem_id
            
        # å‰µå»ºæ–°è¨˜æ†¶
        memory = MemoryItem(
            id=mem_id,
            content=content,
            memory_type=memory_type,
            importance=importance,
            emotional_valence=emotional_valence,
            context_tags=context_tags or []
        )
        
        # çŸ­æœŸè¨˜æ†¶ç·©è¡å€
        self.short_term_buffer[mem_id] = memory
        self.memory_traces[mem_id] = deque(maxlen=20)
        
        self.stats['total_memories'] += 1
        
        return mem_id
    
    def recall(self, query: Any, top_k: int = 5) -> List[MemoryItem]:
        """æª¢ç´¢è¨˜æ†¶"""
        # æœç´¢ç›¸é—œè¨˜æ†¶
        candidates = []
        
        # æœç´¢çŸ­æœŸè¨˜æ†¶
        for mem in self.short_term_buffer.values():
            score = self._calculate_relevance(mem, query)
            if score > 0:
                candidates.append((mem, score))
                
        # æœç´¢é•·æœŸè¨˜æ†¶
        for mem in self.long_term_memory.values():
            score = self._calculate_relevance(mem, query)
            if score > 0:
                candidates.append((mem, score))
        
        # æŒ‰ç›¸é—œæ€§æ’åº
        candidates.sort(key=lambda x: x[1], reverse=True)
        
        # æ›´æ–°è¨ªå•çµ±è¨ˆ
        for mem, _ in candidates[:top_k]:
            mem.access_count += 1
            mem.last_accessed = time.time()
            if mem.id in self.memory_traces:
                self.memory_traces[mem.id].append(time.time())
        
        return [mem for mem, _ in candidates[:top_k]]
    
    def consolidate(self, time_budget_ms: float = 100.0) -> ConsolidationResult:
        """
        è¨˜æ†¶éå›º - ä»¿ç…§æµ·é¦¬é«”çš„ã€Œé‡æ”¾ã€æ©Ÿåˆ¶
        åœ¨ã€Œç¡çœ ã€æˆ–ç©ºé–’æ™‚åŸ·è¡Œ
        """
        start_time = time.time()
        
        promoted = []
        demoted = []
        new_insights = []
        
        # è™•ç†çŸ­æœŸè¨˜æ†¶ç·©è¡å€
        to_promote = []
        to_demote = []
        
        for mem_id, memory in list(self.short_term_buffer.items()):
            # è¨ˆç®—éå›ºåˆ†æ•¸
            consolidation_score = self._calculate_consolidation_score(memory)
            
            if consolidation_score > 0.7:
                # æå‡åˆ°é•·æœŸè¨˜æ†¶
                to_promote.append(mem_id)
            elif consolidation_score < 0.2:
                # æ¸›å¼±æˆ–éºå¿˜
                to_demote.append(mem_id)
                
        # åŸ·è¡Œæå‡
        for mem_id in to_promote:
            if mem_id in self.short_term_buffer:
                memory = self.short_term_buffer.pop(mem_id)
                memory.consolidation_level = 3
                self.long_term_memory[mem_id] = memory
                promoted.append(mem_id)
                
        # åŸ·è¡Œæ¸›å¼±
        for mem_id in to_demote:
            if mem_id in self.short_term_buffer:
                del self.short_term_buffer[mem_id]
                del self.memory_traces[mem_id]
                demoted.append(mem_id)
                
        # å°‹æ‰¾æ¨¡å¼/æ´å¯Ÿ
        patterns = self._find_patterns()
        new_insights = [p for p in patterns if p not in self.long_term_memory]
        
        # å­˜å„²æ´å¯Ÿç‚ºæ–°è¨˜æ†¶
        for insight in new_insights:
            self.store(insight, memory_type='semantic', importance=0.8)
            
        energy_spent = (time.time() - start_time) * 1000  # ms
        
        self.stats['consolidations'] += 1
        self.stats['promoted_to_ltm'] += len(promoted)
        self.stats['forgotten'] += len(demoted)
        
        return ConsolidationResult(
            promoted_memories=promoted,
            demoted_memories=demoted,
            new_insights=new_insights,
            total_energy_spent=energy_spent
        )
    
    def _calculate_relevance(self, memory: MemoryItem, query: Any) -> float:
        """è¨ˆç®—è¨˜æ†¶èˆ‡æŸ¥è©¢çš„ç›¸é—œæ€§"""
        query_str = str(query).lower()
        content_str = str(memory.content).lower()
        
        # é—œéµè©åŒ¹é…
        query_words = set(query_str.split())
        content_words = set(content_str.split())
        overlap = len(query_words & content_words)
        
        if overlap == 0:
            return 0.0
            
        # ç¶œåˆåˆ†æ•¸ = åŒ¹é…åº¦ Ã— é‡è¦æ€§ Ã— è¨ªå•é »ç‡è¡°æ¸›
        match_score = overlap / max(len(query_words), 1)
        importance_factor = memory.importance
        recency_factor = self._calculate_recency(memory)
        
        return match_score * importance_factor * (0.5 + 0.5 * recency_factor)
    
    def _calculate_recency(self, memory: MemoryItem) -> float:
        """è¨ˆç®—æ™‚é–“è¡°æ¸›"""
        time_diff = time.time() - memory.last_accessed
        return max(0.1, 1.0 - (time_diff / (86400 * 7)))  # 7å¤©è¡°æ¸›
    
    def _calculate_consolidation_score(self, memory: MemoryItem) -> float:
        """è¨ˆç®—è¨˜æ†¶éå›ºåˆ†æ•¸"""
        # å› ç´ :
        # 1. é‡è¦æ€§
        # 2. è¨ªå•é »ç‡
        # 3. æƒ…æ„Ÿå¼·åº¦
        # 4. é–“éš”è¤‡ç¿’
        
        importance = memory.importance
        frequency = min(1.0, memory.access_count / 10)
        emotion = abs(memory.emotional_valence)
        
        # è¨ˆç®—è¤‡ç¿’é–“éš”
        traces = self.memory_traces.get(memory.id, deque())
        if len(traces) >= 2:
            intervals = [traces[i+1] - traces[i] for i in range(len(traces)-1)]
            avg_interval = sum(intervals) / len(intervals)
            # é–“éš”è¶Šè¦å¾‹ï¼Œéå›ºè¶Šå¥½
            spacing_score = min(1.0, avg_interval / 3600)  # ç†æƒ³é–“éš”1å°æ™‚
        else:
            spacing_score = 0.3
            
        return (
            0.3 * importance +
            0.25 * frequency +
            0.2 * emotion +
            0.25 * spacing_score
        )
    
    def _reinforce(self, mem_id: str):
        """å¼·åŒ–ç¾æœ‰è¨˜æ†¶"""
        for storage in [self.short_term_buffer, self.long_term_memory]:
            if mem_id in storage:
                storage[mem_id].importance = min(1.0, storage[mem_id].importance + 0.1)
                storage[mem_id].access_count += 1
                return True
        return False
    
    def _find_patterns(self) -> List[str]:
        """å°‹æ‰¾è¨˜æ†¶æ¨¡å¼ - ä»¿ç…§è¨˜æ†¶é‡çµ„"""
        patterns = []
        
        # ç°¡åŒ–çš„æ¨¡å¼æª¢æ¸¬: ç¶“å¸¸ä¸€èµ·è¨ªå•çš„è¨˜æ†¶
        # å¯¦éš›å¯¦ç¾æ‡‰è©²ä½¿ç”¨æ›´è¤‡é›œçš„é—œè¯åˆ†æ
        
        if len(self.short_term_buffer) < 3:
            return patterns
            
        # æª¢æ¸¬é«˜é »å…±åŒè¨ªå•
        # (é€™è£¡æ˜¯ç°¡åŒ–ç‰ˆæœ¬)
        patterns.append("Frequent patterns detected in recent memory access")
        
        return patterns
    
    def _generate_id(self, content: Any) -> str:
        """ç”Ÿæˆè¨˜æ†¶ ID"""
        content_str = str(content)
        hash_input = f"{content_str}_{time.time()}"
        return hashlib.md5(hash_input.encode()).hexdigest()[:12]
    
    def get_stats(self) -> Dict:
        """ç²å–çµ±è¨ˆ"""
        return {
            **self.stats,
            'short_term_count': len(self.short_term_buffer),
            'long_term_count': len(self.long_term_memory),
            'total': len(self.short_term_buffer) + len(self.long_term_memory)
        }


# ============================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================

if __name__ == "__main__":
    # åˆå§‹åŒ–æµ·é¦¬é«”è¨˜æ†¶ç³»çµ±
    hippocampus = HippocampalMemory()
    
    print("=" * 60)
    print("ğŸ§  HIPPOCAMPAL MEMORY SYSTEM")
    print("=" * 60)
    
    # å­˜å„²å„ç¨®è¨˜æ†¶
    print("\nğŸ“ Storing memories...")
    
    hippocampus.store(
        "Harry-001 v4.0 created on 2026-02-01",
        memory_type='episodic',
        importance=0.9,
        emotional_valence=0.5,  # Positive
        context_tags=['creation', 'identity']
    )
    
    hippocampus.store(
        "Attention mechanism implemented",
        memory_type='procedural',
        importance=0.8,
        emotional_valence=0.3,
        context_tags=['brain', 'coding']
    )
    
    hippocampus.store(
        "Moltbook API is read-only",
        memory_type='semantic',
        importance=0.6,
        emotional_valence=-0.2,  # Slight frustration
        context_tags=['api', 'moltbook']
    )
    
    hippocampus.store(
        "Ar Hei said: 'å””æ´—wait my instruction'",
        memory_type='episodic',
        importance=0.9,
        emotional_valence=0.6,
        context_tags=['instruction', 'autonomy']
    )
    
    hippocampus.store(
        "Weather check routine",
        memory_type='procedural',
        importance=0.3,
        emotional_valence=0.0,
        context_tags=['routine', 'weather']
    )
    
    # æ¨¡æ“¬å¤šæ¬¡è¨ªå•
    print("\nğŸ”„ Simulating memory access...")
    for _ in range(5):
        hippocampus.recall("Harry-001")
        hippocampus.recall("attention")
    
    # åŸ·è¡Œè¨˜æ†¶éå›º
    print("\nğŸ’¤ Performing memory consolidation (sleep cycle)...")
    result = hippocampus.consolidate()
    
    print(f"\nâœ… Consolidation Results:")
    print(f"   â€¢ Promoted to LTM: {len(result.promoted_memories)}")
    print(f"   â€¢ Demoted/Forgotten: {len(result.demoted_memories)}")
    print(f"   â€¢ New insights: {len(result.new_insights)}")
    print(f"   â€¢ Energy spent: {result.total_energy_spent:.2f}ms")
    
    # æ¸¬è©¦è¨˜æ†¶æª¢ç´¢
    print("\nğŸ” Testing memory recall...")
    recalled = hippocampus.recall("Harry-001", top_k=3)
    
    print(f"\nğŸ“Œ Top memories for 'Harry-001':")
    for mem in recalled:
        print(f"   â€¢ [{mem.memory_type}] {mem.content[:50]} (importance: {mem.importance})")
    
    # çµ±è¨ˆ
    print("\nğŸ“Š Final Statistics:")
    stats = hippocampus.get_stats()
    for key, value in stats.items():
        print(f"   â€¢ {key}: {value}")
    
    print("\n" + "=" * 60)
    print("âœ… Hippocampal memory system working!")
    print("=" * 60)
